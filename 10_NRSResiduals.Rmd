---
title: "10_NRSResiduals"
output: html_document
---

#Setup

```{r setup, include=FALSE}
suppressPackageStartupMessages({
  library(targets)
  library(tarchetypes)
  library(tidyverse)
  library(performance) # for check_model()
  library(car) # for Anova()
  library(dbplyr) # for window_order
  library(reshape2) # melt()
  library(measurements) # conv_unit and conv_multiunit
  library(maps)
  library(ggspatial) # for maps
  library(ggpmisc) # for stat_poly_eq
  library(mlr3verse) # Machine Learning in R framework, larger universe
  library(GGally) # ggpairs
})
options(scipen = 9) # Use integer notation for numbers under 9 digits
tar_source()
```

## Load targets results from other documents

```{r load tar objects defined elsewhere, eval = FALSE}
tar_load(fiadb)
tar_load(species_crosswalk)
tar_load(nrsgro_plot)
tar_load(nrsgro_plot_stats)
tar_load(nrsgro_ca10_proj_vs_meas)
tar_load(nrsgro_ca10_summary)
tar_load(nrsgro_srvy_summary)
```

## Preload targets results from this document

When tar_make() has already built the objects defined in this document,
run this block to pre-load them. You can then skip running ```{targets} blocks.

```{r load tar objects defined here, eval = FALSE}
get_this_rmd_file() |>
  tar_objects_defined_in_rmd() |>
  tar_load()
```


# Context

## Independent Variables

Decode physigraphic class code
```{targets fiadb_2_5_35_physclcd}
tarchetypes::tar_file_read(
  fiadb_2_5_35_physclcd,
    "data/raw/FIADB_2.5.35_PHYSCLCD.csv",
  read_csv(!!.x, show_col_types = FALSE) |>
    # Remove headers embedded in the table
    filter(!is.na(Code)) |>
    # Make it easier to join
    rename(
      PHYSCLCD = Code,
      PHYSIOGRAPHIC_CLASS = Name
    ) |>
    mutate(
      PHYSIOGRAPHIC_CLASS = as.factor(PHYSIOGRAPHIC_CLASS)
    )
)
```

```{targets nrsres_indep, tar_simple = TRUE}
tmp_plot_stats <- nrsgro_plot_stats |>
  filter_add_stand_id() |>
  group_by(STAND_ID) |>
  arrange(INVYR) |>
  filter(row_number() == 1) |>
  ungroup() |>
  mutate(
    FOREST_TYPE = as.factor(FOREST_TYPE),
    FOREST_TYPE_GROUP = as.factor(FOREST_TYPE_GROUP)
  ) |>
  select(
    STAND_ID,
    BALIVE_METRIC, BA_TREES, QMD,
    FOREST_TYPE_GROUP, FOREST_TYPE, STDAGE
  ) |>
  # Fix the name of this so it's not confusing
  rename(TPA = BA_TREES) |>
  # Compute Stand Density Index; this is not relative stand density, it's the
  # absolute number. See FIADB data dictionary sectino 2.5.139 SDI_RMRS,
  # and VanderSchaaf, C.L., 2013. Reinekeâ€™s stand density index: a quantitative and non-unitless
  # measure of stand density.
  # In: Guldin, James M., ed. 2013. Proceedings of the 15th biennial southern silvicultural
  # research conference. e-Gen. Tech. Rep. SRS-GTR-175. Asheville, NC:
  # US Department of Agriculture, Forest Service, Southern Research Station.
  # 577-579. (Vol. 175, pp. 577-579).
  # Here we use 1.605 as the exponent of Reineke's equation, as is commonly reported.
  mutate(SDI = 10^(log10(TPA) + 1.605*log10(QMD) - 1.605))

tmp_cond_stats <- fia_conds(fiadb, nrsgro_plot) |>
  filter(!is.na(SLOPE) & !is.na(ASPECT)) |>
  # Pick just the first inventory year; this
  # will align best with other starting conditions.
  group_by(STATECD, COUNTYCD, PLOT, CONDID) |>
  arrange(INVYR) |>
  filter(row_number() == 1) |>
  ungroup() |>
  # Pick the largest condition; this will
  # cover the most conditions on the plot
  group_by(STATECD, COUNTYCD, PLOT) |>
  arrange(desc(CONDPROP_UNADJ)) |>
  filter(row_number() == 1) |>
  ungroup() |>
  left_join(
    fiadb_2_5_35_physclcd |>
      mutate(
        SITE_MOISTURE = case_when(
          `Site Type` == "Xeric" ~ 0,
          `Site Type` == "Mesic" ~ 0.5,
          `Site Type` == "Hydric" ~ 1
        )
      ) |>
      select(PHYSCLCD, SITE_MOISTURE, PHYSIOGRAPHIC_CLASS),
    by = join_by(PHYSCLCD)
  ) |>
  filter_add_stand_id() |>
  select(STAND_ID, SLOPE, ASPECT, SITE_MOISTURE, PHYSIOGRAPHIC_CLASS) |>
  mutate(
    ASPECT = cos((45 - ASPECT)*pi/180) + 1 # Beers Transformation
  )

nrsgro_plot |>
  filter_add_stand_id() |>
  group_by(STAND_ID) |>
  arrange(INVYR) |>
  mutate(ELEV = max(ELEV, na.rm = TRUE)) |> # some ELEV are NA; replace them
  filter(row_number() == 1) |>
  ungroup() |>
  select(STAND_ID, LAT, LON, ELEV, ECOSUBCD) |>
  mutate(
    ECOCD = substr(ECOSUBCD, 1, nchar(ECOSUBCD) - 1),
    ECOSUBCD = as.factor(ECOSUBCD),
    ECOCD = as.factor(ECOCD)
  ) |>
  left_join(tmp_plot_stats, by = join_by(STAND_ID))  |>
  left_join(tmp_cond_stats, by = join_by(STAND_ID))
```

```{r plot indep vars, eval = FALSE}
nrsres_indep |>
#  filter(FOREST_TYPE_GROUP == "Spruce / fir") |>
  filter(TPA > 10) |>
  ggplot(aes(TPA, BALIVE_METRIC, color = STDAGE + 1, size = QMD)) +
  geom_point(position = "jitter") +
#  facet_wrap("FOREST_TYPE_GROUP") +
  scale_x_continuous(transform = "log10") +
  scale_y_continuous(transform = "log10") +
  scale_color_continuous(transform = "log10")
```

## Dependent Variable(s)

We want to predict bias in predicted carbon storage, probably over 10 years, maybe 20 or 25.

Let's use the Calb10 data for this.

Question: do we want this per stand, or per tree?

Per stand:
- It's what FVS gives us as primary output
- It's what we'll use in analysis of COP

Per tree:
- Isolates the effects of multiple species
- Don't have an easy way to get per-tree carbon from FVS
  - Can correct bias in BAI instead; is that good enough?
- Don't have an easy way to compute carbon
  - Can we use rFIA?
- Don't have an easy way to aggregate to stand level
  - Can we use rFIA?

```{targets nrsres_depen, tar_simple = TRUE}
nrsgro_ca10_proj_vs_meas |>
  # Filter to only the final projection for each stand
  group_by(StandID) |>
  arrange(desc(ProjectionYears)) |>
  filter(row_number() == 1) |>
  ungroup() |>
  select(-BALIVE_METRIC) # BALIVE_METRIC is a copy of the one in independent vars
```

## Observations

Combine independent and dependent variables into observations
```{targets nrsres_obs, tar_simple = TRUE}
nrsres_obs <- nrsres_depen |>
  left_join(nrsres_indep, by = join_by(StandID == STAND_ID))
```

```{r plot obs hist, eval = FALSE}
nrsres_obs |>
  ggplot(aes(Carbon_Flux_Residual)) +
  geom_histogram(binwidth = 0.1) +
  scale_x_continuous(name = bquote("Carbon Flux Residual" ~ (`Mg C` %.% ha^-1 %.% year^-1))) +
  scale_y_continuous(name = "Number of Plots") +
  theme_bw() +
  ggtitle("Histogram of Carbon Flux Residual")
```

Which hints at what we're trying to fix:

```{r plot density, eval = FALSE}
nrsres_obs |>
  select(StandID, BAI_Srvy, BAI_Calb, BAI_Residual) |>
  pivot_longer(
    cols = c("BAI_Srvy", "BAI_Calb", "BAI_Residual"),
    names_to = "Series",
    values_to = "BAI"
  ) |>
  ggplot(aes(BAI, fill = Series)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = 0, color = "black", linewidth = 0.25) +
  theme_bw() +
  xlab(bquote("Basal Area Increment" ~ (m^2 %.% ha^-1 %.% year^-1))) +
  ylab("Density") +
  scale_fill_viridis_d() +
  ggtitle("Basal Area Increment Projection")
```

### vs Uncalibrated

For giggles, let's look at how FVS does without calibration

```{r nrsres_observed vs calibrated vs uncalibrated, eval = FALSE}
tar_load(nrsgro_none_proj_vs_meas)
nrsres_obs |>
  select(StandID, BAI_Srvy, BAI_Calb) |>
  left_join(
    nrsgro_none_proj_vs_meas |>
      group_by(StandID) |>
      arrange(desc(Projection_Years)) |>
      filter(row_number() == 1) |>
      ungroup() |>
      select(StandID, Projected_BAI) |>
      rename(BAI_None = Projected_BAI),
    by = join_by(StandID)
  ) |>
  pivot_longer(
    cols = c("BAI_Srvy", "BAI_Calb", "BAI_None"),
    names_to = "Series",
    values_to = "BAI"
  ) |>
  ggplot(aes(BAI, fill = Series)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = 0, color = "black", linewidth = 0.25) +
  theme_bw() +
  xlab(bquote("Basal Area Increment" ~ (m^2 %.% ha^-1 %.% year^-1))) +
  ylab("Kernel Density") +
  scale_fill_viridis_d(labels = c("FVS Calibrated", "FVS Default", "FIA Observed")) +
  ggtitle("Basal Area Increment Projection")
```

## Bias by starting BA

```{r bias by starting ba, eval = FALSE}
nrsres_obs |>
  ggplot(aes(BALIVE_METRIC, BAI_Residual, color = FOREST_TYPE_GROUP)) +
  geom_hline(yintercept = 0, color = "black", linewidth = 0.25) +
  geom_point(aes(fill = FOREST_TYPE_GROUP), shape = 21, size = 1, color = "black") +
  stat_poly_line(formula = y ~ x, se = FALSE) +
  geom_hline(yintercept = 0, color = "black", linewidth = 0.25) +
  scale_fill_viridis_d(name = "Forest Type Group") +
  scale_color_viridis_d(name = "Forest Type Group") +
  theme_bw() +
  ggtitle("FVS BAI vs Starting Stand BA") +
  xlab(bquote("Starting Stand Basal Area" ~ (m^2 %.% hectare^-1))) +
  ylab(bquote("Basal Area Increment Residual" ~ (m^2 %.% hectare^-1 %.% year^-1)))
```

# Carbon Flux Bias Correction

## Linearity

Let's look at the independent variables and see if their (rough) relationship
with annual carbon flux is linear

### Latitude

```{r lat linearity, eval = FALSE}
nrsres_obs |>
  ggplot(aes(LAT, Carbon_Flux_Residual)) +
  geom_point(size=0.25) +
  facet_wrap("FOREST_TYPE_GROUP") +
  stat_poly_line(formula = y ~ x, se = FALSE, linewidth = 0.25, color = "blue") +
  stat_poly_eq(use_label("eq", "R2"), formula = y ~ x, color = "blue")
```

### Longitude

```{r lon linearity, eval = FALSE}
nrsres_obs |>
  ggplot(aes(LON, Carbon_Flux_Residual)) +
  geom_point(size=0.25) +
  facet_wrap("FOREST_TYPE_GROUP") +
  stat_poly_line(formula = y ~ x, se = FALSE, linewidth = 0.25, color = "blue") +
  stat_poly_eq(use_label("eq", "R2"), formula = y ~ x, color = "blue")
```

### Elevation

```{r elev linearity, eval = FALSE}
nrsres_obs |>
  ggplot(aes(ELEV, Carbon_Flux_Residual)) +
  geom_point(size=0.25) +
  facet_wrap("FOREST_TYPE_GROUP") +
  stat_poly_line(formula = y ~ x, se = FALSE, linewidth = 0.25, color = "blue") +
  stat_poly_eq(use_label("eq", "R2"), formula = y ~ x, color = "blue")
```

### Slope

```{r slope linearity, eval = FALSE}
nrsres_obs |>
  ggplot(aes(SLOPE, Carbon_Flux_Residual)) +
  geom_point(size=0.25) +
  facet_wrap("FOREST_TYPE_GROUP") +
  stat_poly_line(formula = y ~ x, se = FALSE, linewidth = 0.25, color = "blue") +
  #stat_poly_eq(use_label("eq", "R2"), formula = y ~ x, color = "blue") +
  ggtitle("Slope Linearity")
```

### Aspect

```{r aspect linearity, eval = FALSE}
nrsres_obs |>
  ggplot(aes(ASPECT, Carbon_Flux_Residual)) +
  geom_point(size=0.25) +
  facet_wrap("FOREST_TYPE_GROUP") +
  stat_poly_line(formula = y ~ x, se = FALSE, linewidth = 0.25, color = "blue") +
  #stat_poly_eq(use_label("eq", "R2"), formula = y ~ x, color = "blue") +
  ggtitle("Slope Linearity")
```

### Physiographic class

```{r physclcd linearity, eval = FALSE}
nrsres_obs |>
  ggplot(aes(PHYSIOGRAPHIC_CLASS, Carbon_Flux_Residual)) +
  geom_point(size=0.25) +
  facet_wrap("FOREST_TYPE_GROUP") +
  stat_poly_line(formula = y ~ x, se = FALSE, linewidth = 0.25, color = "blue") +
  #stat_poly_eq(use_label("eq", "R2"), formula = y ~ x, color = "blue") +
  ggtitle("Slope Linearity")
```


### Basal Area

```{r balive linearity, eval = FALSE}
nrsres_obs |>
  mutate(BALIVE_METRIC = cut(BALIVE_METRIC, 0:19 * 5, include.lowest = TRUE)) |>
  ggplot(aes(BALIVE_METRIC, Carbon_Flux_Residual)) +
  geom_boxplot(size=0.25, outlier.size = 0.1) +
#  facet_wrap("FOREST_TYPE_GROUP") +
  stat_poly_line(formula = y ~ x, se = FALSE, linewidth = 0.25, color = "blue") +
  stat_poly_eq(use_label("eq", "R2"), formula = y ~ x, color = "blue") +
  theme_bw()
```

### TPA

```{r TPA linearity, eval = FALSE}
nrsres_obs |>
  ggplot(aes(TPA, Carbon_Flux_Residual)) +
  geom_point(size=0.25) +
  facet_wrap("FOREST_TYPE_GROUP") +
  stat_poly_line(formula = y ~ x, se = FALSE, linewidth = 0.25, color = "blue") +
  stat_poly_eq(use_label("eq", "R2"), formula = y ~ x, color = "blue")
```

### Stand Age

```{r stdage linearity, eval = FALSE}
nrsres_obs |>
  ggplot(aes(STDAGE, Carbon_Flux_Residual)) +
  geom_point(size=0.25) +
  facet_wrap("FOREST_TYPE_GROUP") +
  stat_poly_line(formula = y ~ x, se = FALSE, linewidth = 0.25, color = "blue") +
  stat_poly_eq(use_label("eq", "R2"), formula = y ~ x, color = "blue")
```

### QMD

```{r qmd linearity, eval = FALSE}
nrsres_obs |>
  ggplot(aes(QMD, Carbon_Flux_Residual)) +
  geom_point(size=0.25) +
  facet_wrap("FOREST_TYPE_GROUP") +
  stat_poly_line(formula = y ~ x, se = FALSE, linewidth = 0.25, color = "blue") +
  stat_poly_eq(use_label("eq", "R2"), formula = y ~ x, color = "blue")
```

### SDI

```{r sdi linearity, eval = FALSE}
nrsres_obs |>
  ggplot(aes(SDI, Carbon_Flux_Residual)) +
  geom_point(size=0.25) +
  facet_wrap("FOREST_TYPE_GROUP") +
  stat_poly_line(formula = y ~ x, se = FALSE, linewidth = 0.25, color = "blue") +
  stat_poly_eq(use_label("eq", "R2"), formula = y ~ x, color = "blue")
```


## Model All Independent Variables

Throw all the independent variables into a pot and see what sorts out.

```{r m_all, eval = FALSE}
m_all <- lm(
  data = nrsres_obs,
  formula = Carbon_Flux_Residual ~ LAT + LON + ELEV + SLOPE + ASPECT + BALIVE_METRIC + TPA + QMD + SDI + STDAGE + PHYSIOGRAPHIC_CLASS + FOREST_TYPE_GROUP + ProjectionYears
)
summary(m_all)
Anova(m_all)
```

This is blank; check_model can't handle models with more than one factor.

```{r check m_all, eval = FALSE}
check_model(m_all)
```

Let's take a look at carbon flux projection, adjusted by the model

```{r m_all density, eval = FALSE}
nrsres_obs |>
  mutate(Carbon_Flux_Adj = Carbon_Flux_Calb - unname(predict(m_all, nrsres_obs))) |>
  select(StandID, Carbon_Flux_Srvy, Carbon_Flux_Calb, Carbon_Flux_Adj) |>
  pivot_longer(
    cols = c("Carbon_Flux_Srvy", "Carbon_Flux_Calb", "Carbon_Flux_Adj"),
    names_to = "Series",
    values_to = "Carbon_Flux"
  ) |>
  ggplot(aes(Carbon_Flux, fill = Series)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = 0, color = "black", linewidth = 0.25) +
  theme_bw() +
  xlab(bquote("Carbon Flux" ~ (`Mg C` %.% ha^-1 %.% year^-1))) +
  ylab("Density") +
  scale_fill_viridis_d() +
  ggtitle("Carbon Flux Projection")

```

That looks differently bad, but not good.

## Model P<0.001 Variables

It looks like LON, TPA, and STDAGE aren't contributing, so let's take them out.
BALIVE and SDI conflict with each other (high colinearity).
BALIVE + TPA and QMD conflict with each other.
Remove the derived traits - SDI and QMD.

```{r m_some, eval = FALSE}
m_some <- lm(
  data = nrsres_obs,
  formula = Carbon_Flux_Residual ~ LAT + ELEV + BALIVE_METRIC + TPA + ProjectionYears + FOREST_TYPE_GROUP
)
summary(m_some)
Anova(m_some)
```

```{r m_some density, eval = FALSE}
nrsres_obs |>
  mutate(Carbon_Flux_Adj = Carbon_Flux_Calb - unname(predict(m_some, nrsres_obs))) |>
  select(StandID, Carbon_Flux_Srvy, Carbon_Flux_Calb, Carbon_Flux_Adj) |>
  pivot_longer(
    cols = c("Carbon_Flux_Srvy", "Carbon_Flux_Calb", "Carbon_Flux_Adj"),
    names_to = "Series",
    values_to = "Carbon_Flux"
  ) |>
  ggplot(aes(Carbon_Flux, fill = Series)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = 0, color = "black", linewidth = 0.25) +
  theme_bw() +
  xlab(bquote("Carbon Flux" ~ (`Mg C` %.% ha^-1 %.% year^-1))) +
  ylab("Density") +
  scale_fill_viridis_d() +
  ggtitle("Carbon Flux Projection")
```

Similarly bad.

### SDI

Out of curiosity, let's see what happens if we keep SDI instead of BALIVE.

```{r m_some with sdi, eval = FALSE}
m_some_sdi <- lm(
  data = nrsres_obs,
  formula = Carbon_Flux_Residual ~ LAT + ELEV + SDI + TPA + ProjectionYears + FOREST_TYPE_GROUP
)
summary(m_some_sdi)
Anova(m_some_sdi)

```

```{r m_some_sdi density, eval = FALSE}
nrsres_obs |>
  mutate(Carbon_Flux_Adj = Carbon_Flux_Calb - unname(predict(m_some_sdi, nrsres_obs))) |>
  select(StandID, Carbon_Flux_Srvy, Carbon_Flux_Calb, Carbon_Flux_Adj) |>
  pivot_longer(
    cols = c("Carbon_Flux_Srvy", "Carbon_Flux_Calb", "Carbon_Flux_Adj"),
    names_to = "Series",
    values_to = "Carbon_Flux"
  ) |>
  ggplot(aes(Carbon_Flux, fill = Series)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = 0, color = "black", linewidth = 0.25) +
  theme_bw() +
  xlab(bquote("Carbon Flux" ~ (`Mg C` %.% ha^-1 %.% year^-1))) +
  ylab("Density") +
  scale_fill_viridis_d() +
  ggtitle("Carbon Flux Projection")
```
Pretty much the same.

### ECOCD

Out of curiosity, what happens if we swap FOREST_TYPE_GROUP for ECOCD?

```{r m_some with ecocd, eval = FALSE}
m_some_ecocd <- lm(
  data = nrsres_obs,
  formula = Carbon_Flux_Residual ~ LAT + ELEV + BALIVE_METRIC + TPA + ProjectionYears + ECOCD
)
summary(m_some_ecocd)
Anova(m_some_ecocd)

```


```{r m_some_ecocd density, eval = FALSE}
nrsres_obs |>
  mutate(Carbon_Flux_Adj = Carbon_Flux_Calb - unname(predict(m_some_ecocd, nrsres_obs))) |>
  select(StandID, Carbon_Flux_Srvy, Carbon_Flux_Calb, Carbon_Flux_Adj) |>
  pivot_longer(
    cols = c("Carbon_Flux_Srvy", "Carbon_Flux_Calb", "Carbon_Flux_Adj"),
    names_to = "Series",
    values_to = "Carbon_Flux"
  ) |>
  ggplot(aes(Carbon_Flux, fill = Series)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = 0, color = "black", linewidth = 0.25) +
  theme_bw() +
  xlab(bquote("Carbon Flux" ~ (`Mg C` %.% ha^-1 %.% year^-1))) +
  ylab("Density") +
  scale_fill_viridis_d() +
  ggtitle("Carbon Flux Projection")
```
It does not find ECOCD interesting, and we can't plot the summary when using
ECOCD, so we'll ignore it.

## Scaled Variables

Let's try scaling some things.

```{r m2_scaled, eval = FALSE}
m2_scaled <- lm(
  data = nrsres_obs,
  formula = Carbon_Flux_Residual ~ sin(LAT * pi / 180) + ELEV + sqrt(BALIVE_METRIC) + TPA + ProjectionYears + FOREST_TYPE_GROUP
)
summary(m2_scaled)
Anova(m2_scaled)
```


```{r m2_scaled density, eval = FALSE}
nrsres_obs |>
  mutate(Carbon_Flux_Adj = Carbon_Flux_Calb - unname(predict(m2_scaled, nrsres_obs))) |>
  select(StandID, Carbon_Flux_Srvy, Carbon_Flux_Calb, Carbon_Flux_Adj) |>
  pivot_longer(
    cols = c("Carbon_Flux_Srvy", "Carbon_Flux_Calb", "Carbon_Flux_Adj"),
    names_to = "Series",
    values_to = "Carbon_Flux"
  ) |>
  ggplot(aes(Carbon_Flux, fill = Series)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = 0, color = "black", linewidth = 0.25) +
  theme_bw() +
  xlab(bquote("Carbon Flux" ~ (`Mg C` %.% ha^-1 %.% year^-1))) +
  ylab("Density") +
  scale_fill_viridis_d() +
  ggtitle("Carbon Flux Projection")
```
## No Projection Years

I really want a model that's independent of projection years. We know it'll only
be valid up to ~20 years.
Let's start with all the independent vars again but leave out projection years.

```{r m_timeless_all, eval = FALSE}
m_timeless_all <- lm(
  data = nrsres_obs,
  formula = Carbon_Flux_Residual ~
    # Plot characteristics
    LAT + LON + ELEV + SLOPE + ASPECT +
    # Physiological Characteristics
    PHYSIOGRAPHIC_CLASS +
    # Stand characteristics
    BALIVE_METRIC + TPA + QMD + SDI + STDAGE + FOREST_TYPE_GROUP
)
summary(m_timeless_all)
Anova(m_timeless_all)
```

Well that's completely different.

It seems to like ELEV, PHYSIOGRAPHIC_CLASS, BALIVE, TPA, SDI, STDAGE, and FOREST_TYPE_GROUP.

```{r m_timeless_all density, eval = FALSE}
nrsres_obs |>
  mutate(Carbon_Flux_Adj = Carbon_Flux_Calb - unname(predict(m_timeless_all, nrsres_obs))) |>
  select(StandID, Carbon_Flux_Srvy, Carbon_Flux_Calb, Carbon_Flux_Adj) |>
  pivot_longer(
    cols = c("Carbon_Flux_Srvy", "Carbon_Flux_Calb", "Carbon_Flux_Adj"),
    names_to = "Series",
    values_to = "Carbon_Flux"
  ) |>
  ggplot(aes(Carbon_Flux, fill = Series)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = 0, color = "black", linewidth = 0.25) +
  theme_bw() +
  xlab(bquote("Carbon Flux" ~ (`Mg C` %.% ha^-1 %.% year^-1))) +
  ylab("Density") +
  scale_fill_viridis_d() +
  ggtitle("Carbon Flux Projection")
```
Once again, BALIVE, TPA and SDI are intermixed, so we pick BALIVE and TPA.
BALIVE and STDAGE are colinear, and STDAGE has time baked into it, so we pick BALIVE.

```{r m_timeless, eval = FALSE}
m_timeless <- lm(
  data = nrsres_obs,
  formula = Carbon_Flux_Residual ~ ELEV + PHYSIOGRAPHIC_CLASS + BALIVE_METRIC + FOREST_TYPE_GROUP
)
summary(m_timeless)
print("-----")
Anova(m_timeless)
```


```{r m_timeless density, eval = FALSE}
nrsres_obs |>
  mutate(Carbon_Flux_Adj = Carbon_Flux_Calb - unname(predict(m_timeless, nrsres_obs))) |>
  select(StandID, Carbon_Flux_Srvy, Carbon_Flux_Calb, Carbon_Flux_Adj) |>
  pivot_longer(
    cols = c("Carbon_Flux_Srvy", "Carbon_Flux_Calb", "Carbon_Flux_Adj"),
    names_to = "Series",
    values_to = "Carbon_Flux"
  ) |>
  ggplot(aes(Carbon_Flux, fill = Series)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = 0, color = "black", linewidth = 0.25) +
  theme_bw() +
  xlab(bquote("Carbon Flux" ~ (`Mg C` %.% ha^-1 %.% year^-1))) +
  ylab("Density") +
  scale_fill_viridis_d() +
  ggtitle("Carbon Flux Projection")
```

### Forest Type

What if we use FOREST_TYPE instead of FOREST_TYPE_GROUP?


```{r m_timeless_ungrouped, eval = FALSE}
m_timeless_ungrouped <- lm(
  data = nrsres_obs,
  formula = Carbon_Flux_Residual ~ ELEV + PHYSIOGRAPHIC_CLASS + BALIVE_METRIC + FOREST_TYPE
)
summary(m_timeless_ungrouped)
print("-----")
Anova(m_timeless_ungrouped)
```

So, strictly worse.

```{r m_timeless_ungrouped density, eval = FALSE}
nrsres_obs |>
  mutate(Carbon_Flux_Adj = Carbon_Flux_Calb - unname(predict(m_timeless_ungrouped, nrsres_obs))) |>
  select(StandID, Carbon_Flux_Srvy, Carbon_Flux_Calb, Carbon_Flux_Adj) |>
  pivot_longer(
    cols = c("Carbon_Flux_Srvy", "Carbon_Flux_Calb", "Carbon_Flux_Adj"),
    names_to = "Series",
    values_to = "Carbon_Flux"
  ) |>
  ggplot(aes(Carbon_Flux, fill = Series)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = 0, color = "black", linewidth = 0.25) +
  theme_bw() +
  xlab(bquote("Carbon Flux" ~ (`Mg C` %.% ha^-1 %.% year^-1))) +
  ylab("Density") +
  scale_fill_viridis_d() +
  ggtitle("Carbon Flux Projection")
```


### No Physiographic Class

What if we eliminate physiographic class?

```{r m_timeless_nophys, eval = FALSE}
m_timeless_nophys <- lm(
  data = nrsres_obs,
  formula = Carbon_Flux_Residual ~ ELEV + BALIVE_METRIC + FOREST_TYPE_GROUP
)
summary(m_timeless_nophys)
print("-----")
Anova(m_timeless_nophys)
```

Ironically better.

```{r m_timeless_nophys density, eval = FALSE}
nrsres_obs |>
  mutate(Carbon_Flux_Adj = Carbon_Flux_Calb - unname(predict(m_timeless_nophys, nrsres_obs))) |>
  select(StandID, Carbon_Flux_Srvy, Carbon_Flux_Calb, Carbon_Flux_Adj) |>
  pivot_longer(
    cols = c("Carbon_Flux_Srvy", "Carbon_Flux_Calb", "Carbon_Flux_Adj"),
    names_to = "Series",
    values_to = "Carbon_Flux"
  ) |>
  ggplot(aes(Carbon_Flux, fill = Series)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = 0, color = "black", linewidth = 0.25) +
  theme_bw() +
  xlab(bquote("Carbon Flux" ~ (`Mg C` %.% ha^-1 %.% year^-1))) +
  ylab("Density") +
  scale_fill_viridis_d() +
  ggtitle("Carbon Flux Projection")
```

...though the results still look bad.

### With Plot Metrics

I really want other aspects of the plot to be in there.

```{r m_timeless_plot, eval = FALSE}
m_timeless_plot <- lm(
  data = nrsres_obs,
  formula = Carbon_Flux_Residual ~ LAT + SLOPE + ASPECT + ELEV + PHYSIOGRAPHIC_CLASS + BALIVE_METRIC + FOREST_TYPE_GROUP
)
summary(m_timeless_plot)
print("-----")
Anova(m_timeless_plot)
```

Meh.

```{r m_timeless_plot density, eval = FALSE}
nrsres_obs |>
  mutate(Carbon_Flux_Adj = Carbon_Flux_Calb - unname(predict(m_timeless_plot, nrsres_obs))) |>
  select(StandID, Carbon_Flux_Srvy, Carbon_Flux_Calb, Carbon_Flux_Adj) |>
  pivot_longer(
    cols = c("Carbon_Flux_Srvy", "Carbon_Flux_Calb", "Carbon_Flux_Adj"),
    names_to = "Series",
    values_to = "Carbon_Flux"
  ) |>
  ggplot(aes(Carbon_Flux, fill = Series)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = 0, color = "black", linewidth = 0.25) +
  theme_bw() +
  xlab(bquote("Carbon Flux" ~ (`Mg C` %.% ha^-1 %.% year^-1))) +
  ylab("Density") +
  scale_fill_viridis_d() +
  ggtitle("Carbon Flux Projection")
```

### Without BALive

```{r m_timeless_baless, eval = FALSE}
m_timeless_baless <- lm(
  data = nrsres_obs,
  formula = Carbon_Flux_Residual ~ ELEV + PHYSIOGRAPHIC_CLASS + FOREST_TYPE_GROUP
)
summary(m_timeless_baless)
print("-----")
Anova(m_timeless_baless)
```

Meh. Not as good.

```{r m_timeless_baless density, eval = FALSE}
nrsres_obs |>
  mutate(Carbon_Flux_Adj = Carbon_Flux_Calb - unname(predict(m_timeless_baless, nrsres_obs))) |>
  select(StandID, Carbon_Flux_Srvy, Carbon_Flux_Calb, Carbon_Flux_Adj) |>
  pivot_longer(
    cols = c("Carbon_Flux_Srvy", "Carbon_Flux_Calb", "Carbon_Flux_Adj"),
    names_to = "Series",
    values_to = "Carbon_Flux"
  ) |>
  ggplot(aes(Carbon_Flux, fill = Series)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = 0, color = "black", linewidth = 0.25) +
  theme_bw() +
  xlab(bquote("Carbon Flux" ~ (`Mg C` %.% ha^-1 %.% year^-1))) +
  ylab("Density") +
  scale_fill_viridis_d() +
  ggtitle("Carbon Flux Projection")
```

Still not good.

## More Views

It looks like the best model is m_timeless_nophys, from the perspective
of getting decent results given reliable variables.

```{r apply m5, eval = FALSE}
bias_adjusted <- nrsres_obs |>
  mutate(Carbon_Flux_Bias = unname(predict(m_timeless_nophys, nrsres_obs))) |>
  mutate(
    Carbon_Flux_Adjusted = Carbon_Flux_Calb - Carbon_Flux_Bias,
    Carbon_Flux_BAR = Carbon_Flux_Adjusted - Carbon_Flux_Srvy
  )
```

```{r plot apply m5, eval = FALSE}
bias_adjusted |>
  select(c("FOREST_TYPE_GROUP", "Carbon_Flux_Residual", "Carbon_Flux_BAR")) |>
  pivot_longer(cols = c("Carbon_Flux_Residual", "Carbon_Flux_BAR")) |>
  ggplot(aes(value, fill = name)) +
  geom_vline(xintercept = 0, color = "black", linewidth = 0.25) +
  geom_histogram(binwidth = 0.1, position = "dodge") +
  scale_fill_brewer(name = "Series", labels = c("Adjusted", "Original"), palette="Set1") +
  coord_cartesian(xlim = c(-5, 5)) +
  #facet_wrap("FOREST_TYPE_GROUP") +
  theme_bw() +
  scale_x_continuous(name = bquote("Carbon Flux Residual" ~ (`Mg C` %.% hectare^-1 %.% year^-1))) +
  scale_y_continuous(name = "Number of Plots") +
  ggtitle("Bias-Adjusted Carbon Flux Residuals")
```

### Residual by Starting Stand BA

```{r plot carbon flux residual vs balive, eval = FALSE}
bias_adjusted |>
  mutate(BALIVE_METRIC = cut(BALIVE_METRIC, 0:19 * 5, include.lowest = TRUE)) |>
  ggplot(aes(BALIVE_METRIC, Carbon_Flux_BAR)) +
  geom_point(size=0.25) +
  stat_poly_line(formula = y ~ x, se = FALSE, linewidth = 1, color = "blue") +
  stat_poly_eq(use_label("eq", "R2"), formula = y ~ x, color = "blue") +
  theme_bw() +
  xlab(bquote("Starting Basal Area" ~ (m^2 %.% hectare^-1))) +
  ylab(bquote("Carbon Flux Residual" ~ (`Mg C` %.% hectare^-1 %.% year^-1))) +
  ggtitle("Carbon Flux Residual vs. Stand Starting Basal Area (with bias correction)") +
  geom_boxplot(outlier.size = 0.1, varwidth = TRUE) +
  coord_cartesian(ylim = c(-5, 5))

```

The curve is still there, but now it's a bow, and shifted toward zero.

```{r scatter plot carbon flux residual vs balive, eval = FALSE}
bias_adjusted |>
  ggplot(aes(BALIVE_METRIC, Carbon_Flux_BAR)) +
  geom_point(size=0.25) +
  stat_poly_line(formula = y ~ x, se = FALSE, linewidth = 1, color = "blue") +
  stat_poly_eq(use_label("eq", "R2"), formula = y ~ x, color = "blue") +
  geom_hline(yintercept = 0, color = "black", linewidth = 0.25) +
  theme_bw() +
  xlab(bquote("Starting Basal Area" ~ (m^2 %.% hectare^-1))) +
  ylab(bquote("Carbon Flux Residual" ~ (`Mg C` %.% hectare^-1 %.% year^-1))) +
  ggtitle("Carbon Flux Residual vs. Stand Starting Basal Area (Bias Corrected)") +
#  labs(caption = "With 10-year calibration") +
  scale_y_continuous(limits = c(-10, 5))
```

The bow and shift make the trend flat linear, but the distribution still looks
significantly non-linear.

### Bias-Corrected vs. Measured Flux

```{r proj_vs_meas_carbon_flux, eval = FALSE}
bias_adjusted |>
  ggplot(aes(Carbon_Flux_Srvy, Carbon_Flux_Adjusted)) +
  geom_hline(yintercept = 0, linewidth = 0.25, color = "black") +
  geom_vline(xintercept = 0, linewidth = 0.25, color = "black") +
  geom_abline(intercept = 0, slope = 1, linewidth = 0.25, linetype = "dashed", color = "lightgray") +
  #geom_bin2d(binwidth = 0.5) +
  #scale_fill_viridis_c() +
  geom_point(size = 0.25, alpha = 0.25) +
  # stat_poly_* plots and annotates a fit; they need to be configured to match
  stat_poly_line(
    formula = y ~ x,
    fullrange = TRUE,
    se = FALSE,
    color = "blue",
    linetype = "dashed",
    linewidth = 0.5
  ) +
  stat_poly_eq(use_label("eq", "R2"), formula = y ~ x, size = 3, color = "blue") +
  theme_bw() +
  theme(aspect.ratio = 1) +
  ggtitle("Bias-Corrected vs. Measured Carbon Flux") +
  xlab(bquote("Measured Annual Carbon Flux" ~ (`Mg C` %.% ha^-1 %.% yr^-1))) +
  ylab(bquote("Projected Annual Carbon Flux" ~ (`Mg C` %.% ha^-1 %.% yr^-1))) +
  coord_cartesian(xlim = c(-5, 5), ylim = c(-5, 5))
```

Technically it's less bad, but still pretty bad.

# BAI Bias Correction

Let's take the best model, m_timeless_nophys, and use the same structure to
build a model of BAI prediction bias.

What are we up against?

```{r bai density, eval = FALSE}
nrsres_obs |>
  select(StandID, BAI_Srvy, BAI_Calb) |>
  pivot_longer(
    cols = c("BAI_Srvy", "BAI_Calb"),
    names_to = "Series",
    values_to = "BAI"
  ) |>
  ggplot(aes(BAI, fill = Series)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = 0, color = "black", linewidth = 0.25) +
  theme_bw() +
  xlab(bquote("Basal Area Increment" ~ (m^2 %.% ha^-1 %.% year^-1))) +
  ylab("Density") +
  scale_fill_viridis_d() +
  ggtitle("Basal Area Increment Projection")
```

## Model BAI Bias

```{r m_timeless_bai, eval = FALSE}
m_timeless_bai <- lm(
  data = nrsres_obs,
  formula = BAI_Residual ~ ELEV + BALIVE_METRIC + FOREST_TYPE_GROUP
)
summary(m_timeless_bai)
print("-----")
Anova(m_timeless_bai)
```


```{r check m_timeless_bai, eval = FALSE}
check_model(m_timeless_bai)
```


```{r m_timeless_bai density, eval = FALSE}
bai_adjusted <- nrsres_obs |>
  mutate(
    BAI_Bias = unname(predict(m_timeless_bai, nrsres_obs)),
    BAI_Adj = BAI_Calb - BAI_Bias,
    BAI_BAR = BAI_Adj - BAI_Srvy,
    BA_Adj = BA_Calb - ProjectionYears * BAI_Bias,
    BA_Delta_Adj = BA_Adj - BA_Srvy
  )

bai_adjusted |>
  select(StandID, BAI_Srvy, BAI_Calb, BAI_Adj) |>
  pivot_longer(
    cols = c("BAI_Srvy", "BAI_Calb", "BAI_Adj"),
    names_to = "Series",
    values_to = "BAI"
  ) |>
  ggplot(aes(BAI, fill = Series)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = 0, color = "black", linewidth = 0.25) +
  theme_bw() +
  xlab(bquote("Basal Area Increment" ~ (m^2 %.% ha^-1 %.% year^-1))) +
  ylab("Density") +
  scale_fill_viridis_d() +
  ggtitle("Basal Area Increment Projection")
```

The model's shifted the mean too far, and still has the wrong shape.

## Forest Type

What if we use Forest Type instead of Forest Type Group?

```{r m_timeless_bai_forest_type, eval = FALSE}
m_timeless_bai_forest_type <- lm(
  data = nrsres_obs,
  formula = BAI_Residual ~ ELEV + BALIVE_METRIC + FOREST_TYPE
)
summary(m_timeless_bai_forest_type)
print("-----")
Anova(m_timeless_bai_forest_type)
```

```{r m_timeless_bai_forest_type density, eval = FALSE}
nrsres_obs |>
  mutate(BAI_Adj = BAI_Calb - unname(predict(m_timeless_bai_forest_type, nrsres_obs))) |>
  select(StandID, BAI_Srvy, BAI_Calb, BAI_Adj) |>
  pivot_longer(
    cols = c("BAI_Srvy", "BAI_Calb", "BAI_Adj"),
    names_to = "Series",
    values_to = "BAI"
  ) |>
  ggplot(aes(BAI, fill = Series)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = 0, color = "black", linewidth = 0.25) +
  theme_bw() +
  xlab(bquote("Basal Area Increment" ~ (m^2 %.% ha^-1 %.% year^-1))) +
  ylab("Density") +
  scale_fill_viridis_d() +
  ggtitle("Basal Area Increment Projection")
```

Forest Type Group is a bit better.

## Nik's Stupid Model

This is frustrating; it seems like I could build a better linear model by hand.
This will shift individual values by the difference in means, and scale by the
difference in standard deviations. So shift-and-scale, by forest type group.

```{r niks stupid model density, eval = FALSE}
difference_in_means = mean(nrsres_obs$BAI_Calb) - mean(nrsres_obs$BAI_Srvy)
ratio_of_sd = sd(nrsres_obs$BAI_Srvy) / sd(nrsres_obs$BAI_Calb)
nrsres_obs |>
  mutate(BAI_Adj = (BAI_Calb - difference_in_means) * ratio_of_sd) |>
  select(StandID, FOREST_TYPE_GROUP, BAI_Srvy, BAI_Calb, BAI_Adj) |>
  pivot_longer(
    cols = c("BAI_Srvy", "BAI_Calb", "BAI_Adj"),
    names_to = "Series",
    values_to = "BAI"
  ) |>
  ggplot(aes(BAI, fill = Series)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = 0, color = "black", linewidth = 0.25) +
  facet_wrap("FOREST_TYPE_GROUP") +
  theme_bw() +
  xlab(bquote("Basal Area Increment" ~ (m^2 %.% ha^-1 %.% year^-1))) +
  ylab("Density") +
  scale_fill_viridis_d() +
  ggtitle("Basal Area Increment Projection")
```

High-level, it seems like this is better than the models that lm is producing.

## Residual by Starting Stand BA

Continuing with the best lm model (not Nik's):

```{r plot bai residual vs balive, eval = FALSE}
bai_adjusted |>
  mutate(BAI_Adj_Residual = BAI_Srvy - BAI_Adj) |>
  select(StandID, BALIVE_METRIC, BAI_Residual, BAI_Adj_Residual) |>
  pivot_longer(
    cols = c("BAI_Residual", "BAI_Adj_Residual"),
    names_to = "Series",
    values_to = "BAI"
  ) |>
  mutate(BALIVE_METRIC = cut(BALIVE_METRIC, 0:19 * 5, include.lowest = TRUE)) |>
  ggplot(aes(BALIVE_METRIC, BAI, fill = Series)) +
  geom_boxplot(outlier.size = 0.1, varwidth = TRUE) +
  geom_hline(yintercept = 0, color = "black", linewidth = 0.25) +
  theme_bw() +
  xlab(bquote("Starting Basal Area" ~ (m^2 %.% hectare^-1))) +
  ylab(bquote("BAI Residual" ~ (m^2 %.% hectare^-1 %.% year^-1))) +
  ggtitle("BAI Residual vs. Stand Starting Basal Area (with bias correction)") +
  scale_fill_viridis_d()
```


```{r bai bias by starting ba, eval = FALSE}
nrsres_obs |>
  group_by(FOREST_TYPE_GROUP) |>
  mutate(FOREST_TYPE_GROUP = paste0(FOREST_TYPE_GROUP, ", n=", n())) |>
  ungroup() |>
  ggplot(aes(BALIVE_METRIC, BAI_Residual, color = FOREST_TYPE_GROUP)) +
  geom_hline(yintercept = 0, color = "black", linewidth = 0.25) +
  geom_point(aes(fill = FOREST_TYPE_GROUP), shape = 21, size = 1, color = "black") +
  stat_poly_line(formula = y ~ x, se = FALSE) +
  geom_hline(yintercept = 0, color = "black", linewidth = 0.25) +
  scale_fill_viridis_d(name = "Forest Type Group") +
  scale_color_viridis_d(name = "Forest Type Group") +
  theme_bw() +
  ggtitle("FVS BAI Residual vs Starting Stand BA") +
  xlab(bquote("Starting Stand Basal Area" ~ (m^2 %.% hectare^-1))) +
  ylab(bquote("Basal Area Increment Residual" ~ (m^2 %.% hectare^-1 %.% year^-1)))
```

```{r bai bias adjusted by starting ba, eval = FALSE}
nrsres_obs |>
  group_by(FOREST_TYPE_GROUP) |>
  mutate(FOREST_TYPE_GROUP = paste0(FOREST_TYPE_GROUP, ", n=", n())) |>
  ungroup() |>
  mutate(BAI_Adj = BAI_Calb - unname(predict(m_timeless_bai, nrsres_obs))) |>
  mutate(BAI_Adj_Residual = BAI_Srvy - BAI_Adj) |>
  ggplot(aes(BALIVE_METRIC, BAI_Adj_Residual, color = FOREST_TYPE_GROUP)) +
  geom_hline(yintercept = 0, color = "black", linewidth = 0.25) +
  geom_point(aes(fill = FOREST_TYPE_GROUP), shape = 21, size = 1, color = "black") +
  stat_poly_line(formula = y ~ x, se = FALSE) +
  geom_hline(yintercept = 0, color = "black", linewidth = 0.25) +
  scale_fill_viridis_d(name = "Forest Type Group") +
  scale_color_viridis_d(name = "Forest Type Group") +
  theme_bw() +
  ggtitle("FVS BAI Residual vs Starting Stand BA (adjusted)") +
  xlab(bquote("Starting Stand Basal Area" ~ (m^2 %.% hectare^-1))) +
  ylab(bquote("Basal Area Increment Residual" ~ (m^2 %.% hectare^-1 %.% year^-1)))
```

## RMSE

```{r rmse, eval = FALSE}
x <- bai_adjusted |>
  mutate(BAI_Adj_Residual = BAI_Srvy - BAI_Adj)
Metrics::rmse(x$BAI_Srvy, x$BAI_Calb)
Metrics::rmse(x$BAI_Srvy, x$BAI_Adj)
```

so RMSE is almost halved.

## Quadratic BAI

What happens if we fit a quadratic model just to starting BA?

```{r m6, eval = FALSE}
m6 <- lm(
  data = nrsres_obs,
  formula = BAI_Residual ~ sqrt(BALIVE_METRIC) + FOREST_TYPE_GROUP
)
summary(m6)
Anova(m6)
```

```{r apply m6, eval = FALSE}
bai_m6 <- nrsres_obs |>
  select(-ends_with("_CTR")) |>
  mutate(BAI_Bias = unname(predict(m6, nrsres_obs))) |>
  mutate(
    BAI_Adjusted = BAI_Calb - BAI_Bias,
    BAI_BAR = BAI_Adjusted - BAI_Srvy
  )
```


```{r plot bai m6, eval = FALSE}
bai_m6 |>
  ggplot(aes(BALIVE_METRIC, BAI_BAR)) +
  geom_point(size=0.25) +
  stat_poly_line(formula = y ~ x, se = FALSE, linewidth = 1, color = "blue") +
  stat_poly_eq(use_label("eq", "R2"), formula = y ~ x, color = "blue") +
  theme_bw() +
  xlab(bquote("Starting Basal Area" ~ (m^2 %.% hectare^-1))) +
  ylab(bquote("BAI Residual" ~ (m^2 %.% hectare^-1 %.% year^-1))) +
  ggtitle("BAI Residual vs. Stand Starting Basal Area (Bias Corrected)")
#  labs(caption = "With 10-year calibration") +
#  scale_y_continuous(limits = c(-5, 5))
```


So, no benefit to using the quadratic there.

### Without elevation

```{r m5_no_elev, eval = FALSE}
m5_no_elev <- lm(
  data = nrsres_obs,
  formula = BAI_Residual ~ BALIVE_METRIC + FOREST_TYPE_GROUP
)
bai_adjusted$no_elev <- unname(predict(m5_no_elev, nrsres_obs))

summary(m5_no_elev)
print("-----")
Anova(m5_no_elev)
```

Seems like elevation actually helps.

## BA Error with BAI Correction

If we apply BAI correction, what does that do to BA error?

```{r ba error, eval = FALSE}
bai_adjusted |>
  select(StandID, BA_Delta_Calb, BA_Delta_Adj) |>
  pivot_longer(
    cols = c("BA_Delta_Calb", "BA_Delta_Adj"),
    names_to = "Series",
    values_to = "BA_Error"
  ) |>
  ggplot(aes(BA_Error, fill = Series)) +
  geom_histogram(binwidth = 2.5, position = "dodge") +
  geom_vline(xintercept = 0, color = "black", linewidth = 0.25) +
  theme_bw() +
  xlab(bquote("Projection Error in Basal Area" ~ (m^2 %.% ha^-1))) +
  ylab("Number of Plots") +
  scale_fill_brewer(name = "Series", labels = c("Bias Corrected", "Original"), palette="Set1") +
  ggtitle("Basal Area Projection Error with Bias Correction")
```

Same, but a straight-up BAI distribution

```{r ba distribution, eval = FALSE}
bai_adjusted |>
  select(StandID, BAI_Srvy, BAI_Calb, BAI_Adj, no_elev) |>
  rename(
    Observed = BAI_Srvy,
    Projected = BAI_Calb,
    Adjusted = BAI_Adj,
    NoElev = no_elev
  ) |>
  pivot_longer(
    cols = c("Observed", "Projected", "Adjusted", "NoElev"),
    names_to = "Series",
    values_to = "BAI"
  ) |>
  mutate(
    Series = ordered(Series, levels = c("Observed", "Projected", "Adjusted", "NoElev"))
  ) |>
  ggplot(aes(BAI, fill = Series)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = 0, color = "black", linewidth = 0.25) +
  theme_bw() +
  xlab(bquote("Basal Area Increment" ~ (m^2 %.% ha^-1 %.% year^-1))) +
  ylab("Density") +
  scale_fill_brewer(name = "Series", labels = c("Observed", "Projected", "Adjusted", "NoElev"), palette="Set1") +
  ggtitle("Basal Area Increment Projection")
```

How does this look on a map?

```{r map bai error, eval = FALSE}
tar_load(fvsne_states)

fvsne_states_map <- fvsne_states |>
  distinct(STATE_NAME) |>
  rename(region = STATE_NAME) |>
  _$region |>
  map_data("state", region = _)

nrsgro_plot_locations <- nrsgro_plot |>
  filter(!is.na(LAT) & !is.na(LON)) |>
  group_by(STATECD, COUNTYCD, PLOT) |>
  filter(row_number() == 1) |>
  ungroup() |>
  rename(lat = LAT, long = LON) |>
  filter_add_stand_id() |>
  select(STAND_ID, lat, long) |>
  left_join(
    bai_adjusted |>
      select(StandID, BA_Delta_Calb, BA_Delta_Adj),
    by = join_by(STAND_ID == StandID)
  )

ggplot(fvsne_states_map, aes(long, lat, group = group)) +
  geom_polygon(fill = "white", color = "black") +
  geom_point(
    nrsgro_plot_locations,
    mapping = aes(group = STAND_ID, color = BA_Delta_Calb),
    size = 0.25
  ) +
  coord_sf(crs = 4326) +
  annotation_scale(location = "br") +
  annotation_north_arrow(
    location = "tl",
    width = unit(1, "cm"),
    pad_x = unit(0.75, "cm"),
    pad_y = unit(0.5, "cm")
  ) +
  theme_bw() +
  theme(legend.position = "bottom") +
  scale_color_viridis_c(name = "BA Residual", limits = c(-30, 30)) +
  ggtitle("Basal Area Residual (uncorrected)")

ggplot(fvsne_states_map, aes(long, lat, group = group)) +
  geom_polygon(fill = "white", color = "black") +
  geom_point(
    nrsgro_plot_locations,
    mapping = aes(group = STAND_ID, color = BA_Delta_Adj),
    size = 0.25
  ) +
  coord_sf(crs = 4326) +
  annotation_scale(location = "br") +
  annotation_north_arrow(
    location = "tl",
    width = unit(1, "cm"),
    pad_x = unit(0.75, "cm"),
    pad_y = unit(0.5, "cm")
  ) +
  theme_bw() +
  theme(legend.position = "bottom") +
  scale_color_viridis_c(name = "BA Residual", limits = c(-30, 30)) +
  ggtitle("Basal Area Residual (corrected)")


```

Pick a plot; show:
- FIA measured BA
- FVS projected BA
- Annualized FIA BAI
- Annualized FVS BAI
- Bias corrected FVS BA

Note that each time you run this, it will pick a different plot.

```{r single stand bias correction, eval = FALSE}
sample_stand <- nrsgro_plot_stats |>
  filter(YEARS > 20) |>
  slice_sample(n=1) |>
  select(STATECD, COUNTYCD, PLOT)

tmp_fia_measured <- sample_stand |>
  inner_join(nrsgro_plot_stats, by = join_by(STATECD, COUNTYCD, PLOT)) |>
  filter_add_stand_id() |>
  select(STAND_ID, MEASYEAR, BALIVE_METRIC) |>
  rename(StandID = STAND_ID, Year = MEASYEAR, FIA_Observed = BALIVE_METRIC) |>
  mutate(FVS_Projected = NA, FVS_Corrected = NA)

tmp_fvs_measured <- sample_stand |>
  filter_add_stand_id() |>
  rename(StandID = STAND_ID) |>
  select(StandID) |>
  inner_join(bai_adjusted, by = join_by(StandID)) |>
  rename(FVS_Projected = BA_Calb) |>
  select(StandID, Year, FVS_Projected) |>
  mutate(FIA_Observed = NA, FVS_Corrected = NA)

tmp_fvs_corrected <- sample_stand |>
  filter_add_stand_id() |>
  rename(StandID = STAND_ID) |>
  select(StandID) |>
  inner_join(bai_adjusted, by = join_by(StandID)) |>
  rename(FVS_Corrected = BA_Adj) |>
  select(StandID, Year, FVS_Corrected) |>
  mutate(FIA_Observed = NA, FVS_Projected = NA)

tmp_fia_measured |>
  union_all(tmp_fvs_measured) |>
  union_all(tmp_fvs_corrected) |>
  pivot_longer(
    cols = c("FIA_Observed", "FVS_Projected", "FVS_Corrected"),
    names_to = "Series"
  ) |>
  filter(!is.na(value)) |>
  ggplot(aes(Year, value, color = Series)) +
  geom_point() +
  scale_y_continuous(limits = c(0, NA)) +
  theme_bw() +
  ggtitle("Basal Area Projection and Correction") +
  xlab("Year") +
  ylab(bquote("Basal Area" ~ (m^2 %.% ha^-1)))
```

# Per-Timestep BA

Can we use per-timestep BA instead of starting stand BA?

Let's start by seeing how well our projected and measured timesteps line up.
 
```{r timestep alignment, eval = FALSE}
timestep_alignment <- nrsgro_ca10_summary |>
  select(StandID, Year) |>
  group_by(StandID) |>
  arrange(desc(Year)) |>
  mutate(StepSize = lag(Year) - Year) |>
  ungroup() |>
  rename(Projection_Year = Year) |>
  left_join(
    nrsgro_srvy_summary |>
      select(StandID, Year) |>
      rename(Measurement_Year = Year),
    by = join_by(StandID),
    relationship = "many-to-many"
  ) |>
  mutate(YearDelta = abs(Projection_Year - Measurement_Year)) |>
  group_by(StandID, Projection_Year) |>
  arrange(YearDelta) |>
  filter(row_number() == 1) |>
  ungroup()

timestep_alignment |>
  #filter(StepSize == 10) |>
  filter(!is.na(StepSize)) |>
  ggplot(aes(StepSize)) +
  geom_histogram(binwidth = 1) +
  scale_y_continuous() #transform = "log10")
```

```{r timesteps by lengtht, eval = FALSE}
timestep_alignment |>
  filter(StepSize == 10) |>
  filter(YearDelta == 0) |>
  nrow() /
  timestep_alignment |>
  filter(StepSize == 10) |>
  nrow()
```

So, 40% of timesteps are length 10, and 70% of timesteps with length 10 land
within 1 year of a measurement.

But I think I wouldn't want to do it this way. I'd want to do a run landing on
each survey year where I can get a 10-year timestep in there.

Proposal 0: (Jonathan's Proposal)
- The model already incorporates BA by virtue of having many stands with different
  BA; use the model as-is.

Proposal 1:
- Since our model of BAI bias is independent of projection years, we can assume
  that it's good up to 4 timesteps.
- For longer runs:
  - Run up to 4 timesteps.
  - Apply BA bias correction proportionately to each tree record
  - Set up the next run, up to 4 timesteps.
    - This will use the new BA as the starting BA
- For harvest:
  - Run up to the pre-harvest timestep.
  - Apply BA bias correction proportionately to each tree record
  - Set up and run a 1-year harvest run (removal will use the corrected biomass)
    - Assume that all harvest impact is stored in the tables that we'll feed 
      back in as input, e.g. down dead, woody debris, etc.
  - Start subsequent post-harvest runs from the post-harvest plot, using the
    post-harvest BA
    - These will be runs with 10-year timesteps
    - No need to re-align with the original series

Proposal 2:
- For each plot, find all surveys that are at least 10 years from the initial survey
- Run FVS in an n-10-1 timestep configuration for each of those (plot, invyr)s
  - These runs will incorporate both regen and 10-year future calibration
- Compute a model of bias for 10-year timesteps given conditions at start and end
  of the 10-year timestep.
  - This doesn't work - we don't have real-world conditions at the start of the
    10-year timestep.
  - We could get close by bias-correcting the short run
  - Which might need a separate model of FVS bias for short runs, which
  - we could build for individual inventories
- For longer runs:
  - Run a 10-year timestep
  - Apply BA bias correction proportionately to each tree record
  - Set up the next 10-year timestep


# Random Forest

Let's see if a random forest can do better.

## Training Data

We need to filter the training data down to just what we want the model to use.

```{r rf_bai_train, eval = FALSE}
rf_bai_train <- nrsres_obs |>
  select(
    BAI_Residual, # Dependent variable
    LAT, ELEV, SLOPE, ASPECT,
    SITE_MOISTURE, PHYSIOGRAPHIC_CLASS,
    FOREST_TYPE, FOREST_TYPE_GROUP, BALIVE_METRIC, TPA
  )
```

## First Version

```{r rf_perm, eval = FALSE}
rf_perm <- ranger::ranger(
  BAI_Residual ~ .,
  data = rf_bai_train,
  num.trees = 10 * (ncol(rf_bai_train) - 1),
  mtry = floor((ncol(rf_bai_train) - 1) / 3),
  respect.unordered.factors = "order",
  importance = "permutation",
  seed = 123
)
nrsres_obs |>
  mutate(BAI_Adj = BAI_Calb - predict(rf_perm, rf_bai_train)$predictions) |>
  select(StandID, BAI_Srvy, BAI_Calb, BAI_Adj) |>
  pivot_longer(
    cols = c("BAI_Srvy", "BAI_Calb", "BAI_Adj"),
    names_to = "Series",
    values_to = "BAI"
  ) |>
  ggplot(aes(BAI, fill = Series)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = 0, color = "black", linewidth = 0.25) +
  theme_bw() +
  xlab(bquote("Basal Area Increment" ~ (m^2 %.% ha^-1 %.% year^-1))) +
  ylab("Density") +
  scale_fill_brewer(palette="Set1") +
  ggtitle("Basal Area Increment Projection")

```

First version already looks much better than any of the linear models.

## Permutation Importance

Try switching from permutation-based importance to impurity:

```{r rf_imp, eval = FALSE}
rf_imp <- ranger::ranger(
  BAI_Residual ~ .,
  data = rf_bai_train,
  mtry = floor((ncol(rf_bai_train) - 1) / 3),
  respect.unordered.factors = "order",
  importance = "impurity",
  seed = 123
)
nrsres_obs |>
  mutate(BAI_Adj = BAI_Calb - predict(rf_imp, rf_bai_train)$predictions) |>
  select(StandID, BAI_Srvy, BAI_Calb, BAI_Adj) |>
  pivot_longer(
    cols = c("BAI_Srvy", "BAI_Calb", "BAI_Adj"),
    names_to = "Series",
    values_to = "BAI"
  ) |>
  ggplot(aes(BAI, fill = Series)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = 0, color = "black", linewidth = 0.25) +
  theme_bw() +
  xlab(bquote("Basal Area Increment" ~ (m^2 %.% ha^-1 %.% year^-1))) +
  ylab("Density") +
  scale_fill_brewer(palette="Set1") +
  ggtitle("Basal Area Increment Projection")
```

Can't tell if they're different.

## Variable Importance

We can use them to find the few most important variables in commmon.

```{r vip rf all, eval = FALSE}
vip::vip(rf_perm, num_features = ncol(rf_bai_train) - 1, geom = "point") +
  ggtitle("Variable Importance (Permutation)") +
  theme_bw()
vip::vip(rf_imp, num_features = ncol(rf_bai_train) - 1, geom = "point") +
  ggtitle("Variable Importance (Impurity)") +
  theme_bw()

```

Eyeballing inflection points is risky, but it looks like
- BALIVE_METRIC
- LAT
- TPA
- ELEV
- FOREST_TYPE

```{r rf_min, eval = FALSE}
rf_imp <- ranger::ranger(
  BAI_Residual ~ .,
  data = rf_bai_train |> select(BAI_Residual, BALIVE_METRIC, LAT, TPA, FOREST_TYPE),
  mtry = floor((ncol(rf_bai_train) - 1) / 3),
  respect.unordered.factors = "order",
  importance = "impurity",
  seed = 123
)
nrsres_obs |>
  mutate(BAI_Adj = BAI_Calb - predict(rf_imp, rf_bai_train)$predictions) |>
  select(StandID, BAI_Srvy, BAI_Calb, BAI_Adj) |>
  pivot_longer(
    cols = c("BAI_Srvy", "BAI_Calb", "BAI_Adj"),
    names_to = "Series",
    values_to = "BAI"
  ) |>
  ggplot(aes(BAI, fill = Series)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = 0, color = "black", linewidth = 0.25) +
  theme_bw() +
  xlab(bquote("Basal Area Increment" ~ (m^2 %.% ha^-1 %.% year^-1))) +
  ylab("Density") +
  scale_fill_brewer(palette="Set1", labels = c("Adjusted", "FVS", "FIA")) +
  ggtitle("Basal Area Increment Projection")
```

Seems like a reasonable set of independent variables.

## Hyperparameter Optimizaiont

Let's see how good we can do using caret.

Caret apparently doesn't declare dependency on packages:
- globals
- lattice
- listenv
- parallelly

```{r rf_imp_opt, eval = FALSE}
rf_imp_opt <- caret::train(
  BAI_Residual ~ .,
  data = rf_bai_train |> select(BAI_Residual, BALIVE_METRIC, LAT, TPA, FOREST_TYPE),
  method = "ranger",
  tuneGrid = expand.grid(
    mtry = c(5, 10, 20, 30, 50),
    splitrule = "variance",
    min.node.size = c(5, 7, 10, 15)
  ),
  trControl = caret::trainControl(method = "cv", number = 5),
  seed = 123
)
```

```{r plot rf_imp_opt correction, eval = FALSE}
nrsres_obs |>
  mutate(BAI_Adj = BAI_Calb - predict(rf_imp_opt, rf_bai_train)) |>
  select(StandID, BAI_Srvy, BAI_Calb, BAI_Adj) |>
  pivot_longer(
    cols = c("BAI_Srvy", "BAI_Calb", "BAI_Adj"),
    names_to = "Series",
    values_to = "BAI"
  ) |>
  ggplot(aes(BAI, fill = Series)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = 0, color = "black", linewidth = 0.25) +
  theme_bw() +
  xlab(bquote("Basal Area Increment" ~ (m^2 %.% ha^-1 %.% year^-1))) +
  ylab("Density") +
  scale_fill_brewer(palette="Set1", labels = c("Adjusted", "FVS", "FIA")) +
  ggtitle("Basal Area Increment Projection")
```

huh i like the unonptimized one better... though i could be using the optimized
one wrong

# MLR

We need a dataset that doesn't include any extraneous variables. We then
bundle that into an MLR task for training a regression model.

```{r tsk_rf_bai_regr, eval = FALSE}
tmp_training_data <- nrsres_obs |>
  select(
    BAI_Residual,
    LAT,
    LON,
    ELEV,
    ECOCD,
    ECOSUBCD,
    BALIVE_METRIC,
    # I dreamed last night (this is true) that I used BA_Calb and Tph_Calb,
    # and it improved the model and model workflow a lot.
    BA_Calb,
    Tph_Calb,
    FOREST_TYPE_GROUP,
    FOREST_TYPE,
    STDAGE,
    SLOPE,
    ASPECT,
    PHYSIOGRAPHIC_CLASS
  ) |>
  rename(
    BA_Start = BALIVE_METRIC,
    BA_Proj = BA_Calb,
    Tph_Proj = Tph_Calb
  )

tsk_rf_bai_regr <- as_task_regr(
  tmp_training_data,
  target = "BAI_Residual"
)
```

```{r autoplot tsk fvs bai residaul, eval = FALSE}
autoplot(tsk_rf_bai_regr)
```

## Feature Importance

### Importance Filters

What models can tell us about feature importance?
```{r convert learners to table, eval = FALSE}
as.data.table(mlr_learners)[
  sapply(properties, \(x) {"importance" %in% x})
]
```

I wonder why `regr.ranger` isn't in there? :shrug:
Ah, it's because `regr.ranger` isn't in `mlr3`, but is pulled in by `mlr3verse`.

Let's keep going:
```{r learn random forest, eval = FALSE}
lrn("regr.ranger")$
  param_set$
  levels$
  importance
```

Cool, cool; let's use ranger to determine feature importance. The `caret` way
is to run once using "impurity" and once using "permutation" and look at what's
above the fold in both.

```{r impurity vs permuation, eval = FALSE}
lrn_ranger_imp = lrn("regr.ranger", importance = "impurity")
lrn_ranger_prm = lrn("regr.ranger", importance = "permutation")
```

Do we have any incomplete rows?
```{r find rows with missing data, eval = FALSE}
length(
  tsk_rf_bai_regr$row_ids[
    !complete.cases(tsk_rf_bai_regr$data())
  ]
)
```
Yes, 12 of them. Remove those for the feature importance task.

```{r remove rows with missing data, eval = FALSE}
tsk_fi = tsk_rf_bai_regr$clone()
tsk_fi$filter(tsk_fi$row_ids[complete.cases(tsk_fi$data())])
```

First with impurity:
```{r feature importance by impurity, eval = FALSE}
flt_importance = flt("importance", learner = lrn_ranger_imp)
flt_importance$calculate(tsk_fi)
as.data.table(flt_importance)
```

But I don't like some of those; what if I remove them?

"I don't like," here means that some of those features are going to be difficult
or impossible to acquire for non-FIA stands. Let's try restricting to features
that will be available for non-FIA stands.

```{targets nrsres_bai_task, tar_simple = TRUE}
fva_bai_residual_training <- nrsres_obs |>
  select(
    BAI_Residual,
    LAT,
#    LON,
    ELEV,
#    ECOCD,
#    ECOSUBCD,
#    BALIVE_METRIC,
    BA_Proj = BA_Calb,
    Tph_Proj = Tph_Calb,
#    FOREST_TYPE_GROUP,
    FOREST_TYPE,
#    STDAGE,
    SLOPE,
    ASPECT,
#    PHYSIOGRAPHIC_CLASS
  )

nrsres_bai_task <- as_task_regr(
  fva_bai_residual_training,
  target = "BAI_Residual"
)

# Remove incomplete rows from training data
nrsres_bai_task$filter(
  nrsres_bai_task$row_ids[complete.cases(nrsres_bai_task$data())]
)
```

```{r features random forest things are important, eval = FALSE}
flt_imp_rstr = flt("importance", learner = lrn_ranger_imp)
flt_imp_rstr$calculate(nrsres_bai_task)
as.data.table(flt_imp_rstr)
flt_prm_rstr = flt("importance", learner = lrn_ranger_prm)
flt_prm_rstr$calculate(nrsres_bai_task)
as.data.table(flt_prm_rstr)

```

Tph_Proj, LAT, BA_Proj, and ELEV are on top for both, followed by FOREST_TYPE_GROUP,
SLOPE, and ASPECT.

### Embedded Importance

Some models can tell us what features they use:

```{r what models can tell us what features they use, eval = FALSE}
as.data.table(mlr_learners)[
  sapply(properties, function(x) "selected_features" %in% x)
]
```

`regr.ranger` is in there again, so we'll use it again.

```{r what features does regr.ranger use, eval = FALSE}
lrn_ranger_imp$train(nrsres_bai_task)
lrn_ranger_imp$selected_features()
```

So, that gives an unranked list, which is less helpful.

## Automated Feature Importance

Of course, mlr3 can automate the process of identifying the features you need
for a good model.

To pick features, we need to know what we're trying to optimize:
```{r mlr optimization measures, eval = FALSE}
as.data.table(mlr_measures)[task_type == "regr",]
```

Without other guidance on what to select, i'll go for the familiar RMSE.

We also need a termination condition:
```{r mlr termination conditions, eval = FALSE}
as.data.table(trm())
```

I have some time, so we'll look for stagnation.

Combine the optimization variable and termination condition into a feature
selection task:

```{r task optimize rmse stagnation, eval = FALSE}
fs_tsk_fvs_bai <- fsi(
  task = nrsres_bai_task,
  learner = lrn_ranger_imp,
  resampling = rsmp("cv", folds = 3),
  measure = msr("regr.rmse"),
  terminator = trm("stagnation", threshold = 1)
)
```

There are a variety of feature selection processes. Sequential, exhaustive
search, etc.; the one that makes intuitive sense to me is "Recursive Feature
Elimination" (rfe), which tries to find and remove low-importance features.

```{r feature selection by recursive feature eliminiation, eval = FALSE}
fs_rfe <- fs("rfe")
fs_rfe$optimize(fs_tsk_fvs_bai)
as.data.table(fs_tsk_fvs_bai$result)[, .("features", "regr.rmse", "regr.sae")]
```

ha, it selected all features.

But it was also fast; let's try an exhaustive search.

```{r feature selection exhaustive search, eval = FALSE}
fs_tsk_all <- fsi(
  task = nrsres_bai_task,
  learner = lrn_ranger_imp,
  resampling = rsmp("cv", folds = 3),
  measure = msrs(c("regr.rmse", "regr.sae")),
  terminator = trm("none")
)
fs_seq <- fs("exhaustive_search")
fs_seq$optimize(fs_tsk_all)
as.data.table(fs_tsk_all$result)[, c("features", "regr.rmse")]
```

So having all features is best, but leaving out ASPECT and FOREST_TYPE_GROUP
reduces RMSE by 0.000227, or 0.07%.

## PCA

I believe that BA_Proj and Tph_Proj are correlated enough to create a principal component;
ELEV, ECOSUBCD, and FOREST_TYPE probably are too.

Let's see:

```{r correlation analysis, eval = FALSE}
as.data.table(nrsres_bai_task) |>
  # Omit factors - they make a mess
  select(-BAI_Residual, -FOREST_TYPE_GROUP) |>
  ggpairs()
```

Well that's unexpected - everything correlates with everything else!

We can do PCA:
```{r pca, eval = FALSE}
fvs_bai_pca <- as.data.table(nrsres_bai_task) |>
  select(-BAI_Residual, -FOREST_TYPE_GROUP) |>
  prcomp(center = TRUE, scale. = TRUE)
summary(fvs_bai_pca)
fvs_bai_pca
```

PCA confirms that everything correlates with everything else.

So PCA isn't going to get us anything, since random forest is already dealing
with this. Also, doing PCA in mlr3 requires buy-in to their pipeline ops,
and that's further than I'm prepared to go at the moment.

## Hyperparameters

So, let's wrap up and finalize this model.

Now that we have a set of features, we need to do hyperparameter optimization.

We've been using `regr.ranger`; let's keep with it.

```{r list regression parameters, eval = FALSE}
as.data.table(lrn("regr.ranger")$param_set)
```

I believe the ones we want to tune are:
- importance ["none", "impurity", "permutation"]
- max.depth [1-Inf] (0 for unlimited, 30 is deep)
- min.node.size [1-Inf] (5+ for regression)
- mtry [1-Inf] (sqrt(# of variables); 2 or 3 for 7 vars) 
- num.trees [1-Inf] (3, 5, other small integer is common; default is 500?!?!)

```{r optimize hyperparameters, eval = FALSE}
fvs_bai_lrn <- lrn(
  "regr.ranger",
  importance = to_tune(c("impurity", "permutation")),
  max.depth = to_tune(1, 100, logscale = TRUE),
  min.node.size = to_tune(1:5 * 3 + 2),
  mtry = to_tune(2:ceiling(sqrt(length(names(nrsres_bai_task$data()))))),
  num.trees = to_tune(1, 100, logscale = TRUE)
)
ti_lrn <- ti( # Section 4.2 says we should use train() or auto_tune() instead of ti()
  task = nrsres_bai_task,
  learner = fvs_bai_lrn,
  resampling = rsmp("cv", folds = 3),
  measures = msr("regr.rmse"),
  terminator = trm("stagnation", threshold = 1)
)
tnr_mbo <- tnr("mbo") # use defaults
tnr_mbo$optimize(ti_lrn)

# Results go into ti_lrn
unlist(ti_lrn$result$x_domain)
```

Note that max.depth and num.trees have log scale, so we need to fetch them from x_domain

This optimization appears to be unstable: it gives significantly different
results on subsequent runs.

Across many runs, it looks like the following parameters should work:

- importance: impurity
- max.depth: 19
- min.node.size: 11
- mtry: 2
- num.trees: 96

## Train and Predict

Now, create, train, and apply an optimized model:
```{targets nrsres_model, tar_simple = TRUE}
# If tuning from the tuner implementation (ti), you can set hyperparameters 
# directly from the tuner:
#   nrsres_model = lrn("regr.ranger")
#   nrsres_model$param_set$values = ti_lrn$result_learner_param_vals
# For reproducibility, we set hyperparameters manually:
nrsres_model = lrn(
  "regr.ranger",
  importance = "impurity",
  max.depth = 19,
  min.node.size = 11,
  mtry = 2,
  num.trees = 96
)
nrsres_model$train(nrsres_bai_task)
nrsres_model # The model must be saved/restored in conjunction with the learner
```

```{r examine model results, eval = FALSE}
# use $predict_newdata() to predict using new data
prediction <- nrsres_model$predict(nrsres_bai_task)
autoplot(prediction)
```

a'ight, let's apply this as a correction, and see how it looks.

```{r apply optimized model, eval = FALSE}
nrsres_obs |>
  mutate(BAI_Adj = BAI_Calb - prediction$response) |>
  select(StandID, BAI_Srvy, BAI_Calb, BAI_Adj) |>
  rename(
    FVS = BAI_Calb,
    FIA = BAI_Srvy,
    ADJ = BAI_Adj
  ) |>
  pivot_longer(
    cols = c("FVS", "FIA", "ADJ"),
    names_to = "Series",
    values_to = "BAI"
  ) |>
  ggplot(aes(BAI, fill = Series)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = 0, color = "black", linewidth = 0.25) +
  theme_bw() +
  xlab(bquote("Basal Area Increment" ~ (m^2 %.% ha^-1 %.% year^-1))) +
  ylab("Kernel Density") +
  scale_fill_brewer(palette="Set1", labels = c("Corrected", "FIA Observed", "FVS Calibrated")) +
  ggtitle("Basal Area Increment Projection")

```

## Residual Residuals

How'd we do?

```{r residual residuals, eval = FALSE}
residual_residuals <- nrsres_obs |>
  mutate(BAI_Adj = BAI_Calb - prediction$response) |>
  group_by(FOREST_TYPE) |>
  summarize(FIA = mean(BAI_Srvy), ADJ = mean(BAI_Adj), DLTA = FIA - ADJ) |>
  ungroup()

```

```{r plot corrected carbon flux residuals, eval = FALSE}
nrsres_obs |>
  mutate(BAI_Adj = BAI_Calb - prediction$response) |>
  select(StandID, BAI_Srvy, BAI_Calb, BAI_Adj) |>
  mutate(RR = BAI_Srvy - BAI_Adj) |>
  ggplot(aes(RR)) +
  geom_histogram(binwidth = 0.01) +
  scale_x_continuous(name = bquote("Carbon Flux Residual" ~ (`Mg C` %.% ha^-1 %.% year^-1))) +
  scale_y_continuous(name = "Number of Plots") +
  theme_bw() +
  ggtitle("Histogram of Carbon Flux Residuals after Correction")

```


```{r plot corrected bai residuals, eval = FALSE}
nrsres_obs |>
  mutate(BAI_Adj = BAI_Calb - prediction$response) |>
  select(StandID, BAI_Srvy, BAI_Calb, BAI_Adj) |>
  mutate(
    RR_Calb = BAI_Srvy - BAI_Calb,
    RR_Pct_Calb = 100 * RR_Calb / BAI_Srvy,
    RR_Adj = BAI_Srvy - BAI_Adj,
    RR_Pct_Adj = 100 * RR_Adj / BAI_Srvy
  ) |>
  pivot_longer(
    cols = c("RR_Pct_Calb", "RR_Pct_Adj"),
    names_to = "Series",
    values_to = "value"
  ) |>
  ggplot(aes(value, fill = Series)) +
  geom_histogram(binwidth = 100, position = "dodge") +
  coord_cartesian(xlim = c(-10000, 10000), ylim = c(0, 100)) +
  scale_x_continuous(name = bquote("Carbon Flux Residual %")) +
  scale_y_continuous(name = "Number of Plots") +
  scale_fill_brewer(palette="Set1", labels = c("Adjusted", "Calibrated")) +
  theme_bw() +
  ggtitle("Histogram of Residual % Before and after Adjustment")

```

## Manually nudge

It really bugs me that the peaks of ADJ and FIA ore off by a skosh. How much
are they off by?

```{r adjust adjusted peak, eval = FALSE}
nrsres_obs |>
  mutate(BAI_Adj = BAI_Calb - prediction$response + 0.05) |>
  select(StandID, BAI_Srvy, BAI_Calb, BAI_Adj) |>
  rename(
    FVS = BAI_Calb,
    FIA = BAI_Srvy,
    ADJ = BAI_Adj
  ) |>
  pivot_longer(
    cols = c("FVS", "FIA", "ADJ"),
    names_to = "Series",
    values_to = "BAI"
  ) |>
  ggplot(aes(BAI, fill = Series)) +
  geom_density(alpha = 0.5) +
  geom_vline(xintercept = 0, color = "black", linewidth = 0.25) +
  theme_bw() +
  xlab(bquote("Basal Area Increment" ~ (m^2 %.% ha^-1 %.% year^-1))) +
  ylab("Density") +
  scale_fill_brewer(palette="Set1") +
  ggtitle("Basal Area Increment Projection")

```
looks like they're off by about 0.05 m^2 %.% ha^-1 %.% year^-1.
